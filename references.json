[
  {
    "publisher": "Elsevier BV",
    "issue": "6",
    "DOI": "10.1016/j.tics.2005.04.010",
    "type": "article-journal",
    "page": "296-305",
    "source": "Crossref",
    "title": "Capacity limits of information processing in the brain",
    "volume": "9",
    "author": [
      {
        "given": "René",
        "family": "Marois"
      },
      {
        "given": "Jason",
        "family": "Ivanoff"
      }
    ],
    "container-title": "Trends in Cognitive Sciences",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2005,
          6
        ]
      ]
    },
    "URL": "https://doi.org/d5gmqt",
    "container-title-short": "Trends in Cognitive Sciences",
    "PMID": "15925809",
    "id": "q5vfV9nk",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1016/j.tics.2005.04.010"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "7957",
    "DOI": "10.1038/d41586-023-01295-4",
    "type": "article-journal",
    "page": "413-413",
    "source": "Crossref",
    "title": "Why open-source generative AI models are an ethical way forward for science",
    "volume": "616",
    "author": [
      {
        "given": "Arthur",
        "family": "Spirling"
      }
    ],
    "container-title": "Nature",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          4,
          18
        ]
      ]
    },
    "URL": "https://doi.org/gsqx6v",
    "container-title-short": "Nature",
    "PMID": "37072520",
    "id": "17E1dWalv",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/d41586-023-01295-4"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "1",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Deep Learning (DL) has recently enabled unprecedented advances in one of the grand challenges in computational biology: the half-century-old problem of protein structure prediction. In this paper we discuss recent advances, limitations, and future perspectives of DL on five broad areas: protein structure prediction, protein function prediction, genome engineering, systems biology and data integration, and phylogenetic inference. We discuss each application area and cover the main bottlenecks of DL approaches, such as training data, problem scope, and the ability to leverage existing DL architectures in new contexts. To conclude, we provide a summary of the subject-specific and general challenges for DL across the biosciences.</jats:p>",
    "DOI": "10.1038/s41467-022-29268-7",
    "type": "article-journal",
    "source": "Crossref",
    "title": "Current progress and open challenges for applying deep learning across the biosciences",
    "volume": "13",
    "author": [
      {
        "given": "Nicolae",
        "family": "Sapoval"
      },
      {
        "given": "Amirali",
        "family": "Aghazadeh"
      },
      {
        "given": "Michael G.",
        "family": "Nute"
      },
      {
        "given": "Dinler A.",
        "family": "Antunes"
      },
      {
        "given": "Advait",
        "family": "Balaji"
      },
      {
        "given": "Richard",
        "family": "Baraniuk"
      },
      {
        "given": "C. J.",
        "family": "Barberan"
      },
      {
        "given": "Ruth",
        "family": "Dannenfelser"
      },
      {
        "given": "Chen",
        "family": "Dun"
      },
      {
        "given": "Mohammadamin",
        "family": "Edrisi"
      },
      {
        "given": "R. A. Leo",
        "family": "Elworth"
      },
      {
        "given": "Bryce",
        "family": "Kille"
      },
      {
        "given": "Anastasios",
        "family": "Kyrillidis"
      },
      {
        "given": "Luay",
        "family": "Nakhleh"
      },
      {
        "given": "Cameron R.",
        "family": "Wolfe"
      },
      {
        "given": "Zhi",
        "family": "Yan"
      },
      {
        "given": "Vicky",
        "family": "Yao"
      },
      {
        "given": "Todd J.",
        "family": "Treangen"
      }
    ],
    "container-title": "Nature Communications",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          1
        ]
      ]
    },
    "URL": "https://doi.org/gp26xk",
    "container-title-short": "Nat Commun",
    "PMCID": "PMC8976012",
    "PMID": "35365602",
    "id": "1AZn5l2ah",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41467-022-29268-7"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "7956",
    "DOI": "10.1038/s41586-023-05881-4",
    "type": "article-journal",
    "page": "259-265",
    "source": "Crossref",
    "title": "Foundation models for generalist medical artificial intelligence",
    "volume": "616",
    "author": [
      {
        "given": "Michael",
        "family": "Moor"
      },
      {
        "given": "Oishi",
        "family": "Banerjee"
      },
      {
        "given": "Zahra Shakeri Hossein",
        "family": "Abad"
      },
      {
        "given": "Harlan M.",
        "family": "Krumholz"
      },
      {
        "given": "Jure",
        "family": "Leskovec"
      },
      {
        "given": "Eric J.",
        "family": "Topol"
      },
      {
        "given": "Pranav",
        "family": "Rajpurkar"
      }
    ],
    "container-title": "Nature",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          4,
          12
        ]
      ]
    },
    "URL": "https://doi.org/gr4td4",
    "container-title-short": "Nature",
    "PMID": "37045921",
    "id": "elx4isXx",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41586-023-05881-4"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "6",
    "DOI": "10.1038/s41587-023-01789-6",
    "type": "article-journal",
    "page": "750-751",
    "source": "Crossref",
    "title": "How will generative AI disrupt data science in drug discovery?",
    "volume": "41",
    "author": [
      {
        "given": "Jean-Philippe",
        "family": "Vert"
      }
    ],
    "container-title": "Nature Biotechnology",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          5,
          8
        ]
      ]
    },
    "URL": "https://doi.org/gsznzd",
    "container-title-short": "Nat Biotechnol",
    "PMID": "37156917",
    "id": "wo7jyZHW",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41587-023-01789-6"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "8",
    "DOI": "10.1038/s41587-023-01848-y",
    "type": "article-journal",
    "page": "1056-1059",
    "source": "Crossref",
    "title": "Democratizing knowledge representation with BioCypher",
    "volume": "41",
    "author": [
      {
        "given": "Sebastian",
        "family": "Lobentanzer"
      },
      {
        "given": "Patrick",
        "family": "Aloy"
      },
      {
        "given": "Jan",
        "family": "Baumbach"
      },
      {
        "given": "Balazs",
        "family": "Bohar"
      },
      {
        "given": "Vincent J.",
        "family": "Carey"
      },
      {
        "given": "Pornpimol",
        "family": "Charoentong"
      },
      {
        "given": "Katharina",
        "family": "Danhauser"
      },
      {
        "given": "Tunca",
        "family": "Doğan"
      },
      {
        "given": "Johann",
        "family": "Dreo"
      },
      {
        "given": "Ian",
        "family": "Dunham"
      },
      {
        "given": "Elias",
        "family": "Farr"
      },
      {
        "given": "Adrià",
        "family": "Fernandez-Torras"
      },
      {
        "given": "Benjamin M.",
        "family": "Gyori"
      },
      {
        "given": "Michael",
        "family": "Hartung"
      },
      {
        "given": "Charles Tapley",
        "family": "Hoyt"
      },
      {
        "given": "Christoph",
        "family": "Klein"
      },
      {
        "given": "Tamas",
        "family": "Korcsmaros"
      },
      {
        "given": "Andreas",
        "family": "Maier"
      },
      {
        "given": "Matthias",
        "family": "Mann"
      },
      {
        "given": "David",
        "family": "Ochoa"
      },
      {
        "given": "Elena",
        "family": "Pareja-Lorente"
      },
      {
        "given": "Ferdinand",
        "family": "Popp"
      },
      {
        "given": "Martin",
        "family": "Preusse"
      },
      {
        "given": "Niklas",
        "family": "Probul"
      },
      {
        "given": "Benno",
        "family": "Schwikowski"
      },
      {
        "given": "Bünyamin",
        "family": "Sen"
      },
      {
        "given": "Maximilian T.",
        "family": "Strauss"
      },
      {
        "given": "Denes",
        "family": "Turei"
      },
      {
        "given": "Erva",
        "family": "Ulusoy"
      },
      {
        "given": "Dagmar",
        "family": "Waltemath"
      },
      {
        "given": "Judith A. H.",
        "family": "Wodke"
      },
      {
        "given": "Julio",
        "family": "Saez-Rodriguez"
      }
    ],
    "container-title": "Nature Biotechnology",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          6,
          19
        ]
      ]
    },
    "URL": "https://doi.org/gszqjr",
    "container-title-short": "Nat Biotechnol",
    "PMID": "37337100",
    "id": "tr1XjZ1R",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41587-023-01848-y"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "1",
    "DOI": "10.1038/s41597-020-0486-7",
    "type": "article-journal",
    "source": "Crossref",
    "title": "The TRUST Principles for digital repositories",
    "volume": "7",
    "author": [
      {
        "given": "Dawei",
        "family": "Lin"
      },
      {
        "given": "Jonathan",
        "family": "Crabtree"
      },
      {
        "given": "Ingrid",
        "family": "Dillo"
      },
      {
        "given": "Robert R.",
        "family": "Downs"
      },
      {
        "given": "Rorie",
        "family": "Edmunds"
      },
      {
        "given": "David",
        "family": "Giaretta"
      },
      {
        "given": "Marisa",
        "family": "De Giusti"
      },
      {
        "given": "Hervé",
        "family": "L’Hours"
      },
      {
        "given": "Wim",
        "family": "Hugo"
      },
      {
        "given": "Reyna",
        "family": "Jenkyns"
      },
      {
        "given": "Varsha",
        "family": "Khodiyar"
      },
      {
        "given": "Maryann E.",
        "family": "Martone"
      },
      {
        "given": "Mustapha",
        "family": "Mokrane"
      },
      {
        "given": "Vivek",
        "family": "Navale"
      },
      {
        "given": "Jonathan",
        "family": "Petters"
      },
      {
        "given": "Barbara",
        "family": "Sierman"
      },
      {
        "given": "Dina V.",
        "family": "Sokolova"
      },
      {
        "given": "Martina",
        "family": "Stockhause"
      },
      {
        "given": "John",
        "family": "Westbrook"
      }
    ],
    "container-title": "Scientific Data",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2020,
          5,
          14
        ]
      ]
    },
    "URL": "https://doi.org/ggwrtj",
    "container-title-short": "Sci Data",
    "PMCID": "PMC7224370",
    "PMID": "32409645",
    "id": "MMp6cQ1x",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41597-020-0486-7"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:title>ABSTRACT</jats:title><jats:p>Cell type annotation is an essential step in single-cell RNA-seq analysis. However, it is a time-consuming process that often requires expertise in collecting canonical marker genes and manually annotating cell types. Automated cell type annotation methods typically require the acquisition of high-quality reference datasets and the development of additional pipelines. We assessed the performance of GPT-4, a highly potent large language model, for cell type annotation, and demonstrated that it can automatically and accurately annotate cell types by utilizing marker gene information generated from standard single-cell RNA-seq analysis pipelines. Evaluated across hundreds of tissue types and cell types, GPT-4 generates cell type annotations exhibiting strong concordance with manual annotations and has the potential to considerably reduce the effort and expertise needed in cell type annotation. We also developed GPTCelltype, an open-source R software package to facilitate cell type annotation by GPT-4.</jats:p>",
    "DOI": "10.1101/2023.04.16.537094",
    "type": "manuscript",
    "source": "Crossref",
    "title": "Assessing GPT-4 for cell type annotation in single-cell RNA-seq analysis",
    "author": [
      {
        "given": "Wenpin",
        "family": "Hou"
      },
      {
        "given": "Zhicheng",
        "family": "Ji"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023,
          4,
          21
        ]
      ]
    },
    "URL": "https://doi.org/gsznzg",
    "PMCID": "PMC10153208",
    "PMID": "37131626",
    "id": "ae7XiPvs",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/2023.04.16.537094"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Large Language Models (LLMs) have shown great promise in their knowledge integration and problem-solving capabilities, but their ability to assist in bioinformatics research has not been systematically evaluated. To bridge this gap, we present BioLLMBench, a novel benchmarking framework coupled with a scoring metric scheme for comprehensively evaluating LLMs in solving bioinformatics tasks. Through BioLLMBench, we conducted a thorough evaluation of 2,160 experimental runs of the three most widely used models, GPT-4, Bard and LLaMA, focusing on 36 distinct tasks within the field of bioinformatics. The tasks come from six key areas of emphasis within bioinformatics that directly relate to the daily challenges and tasks faced by individuals within the field. These areas are domain expertise, mathematical problem-solving, coding proficiency, data visualization, summarizing research papers, and developing machine learning models. The tasks also span across varying levels of complexity, ranging from fundamental concepts to expert-level challenges. Each key area was evaluated using seven specifically designed task metrics, which were then used to conduct an overall evaluation of the LLM’s response. To enhance our understanding of model responses under varying conditions, we implemented a Contextual Response Variability Analysis. Our results reveal a diverse spectrum of model performance, with GPT-4 leading in all tasks except mathematical problem solving. GPT4 was able to achieve an overall proficiency score of 91.3% in domain knowledge tasks, while Bard excelled in mathematical problem-solving with a 97.5% success rate. While GPT-4 outperformed in machine learning model development tasks with an average accuracy of 65.32%, both Bard and LLaMA were unable to generate executable end-to-end code. All models faced considerable challenges in research paper summarization, with none of them exceeding a 40% score in our evaluation using the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score, highlighting a significant area for future improvement. We observed an increase in model performance variance when using a new chatting window compared to using the same chat, although the average scores between the two contextual environments remained similar. Lastly, we discuss various limitations of these models and acknowledge the risks associated with their potential misuse.</jats:p>",
    "DOI": "10.1101/2023.12.19.572483",
    "type": "manuscript",
    "source": "Crossref",
    "title": "BioLLMBench: A Comprehensive Benchmarking of Large Language Models in Bioinformatics",
    "author": [
      {
        "given": "Varuni",
        "family": "Sarwal"
      },
      {
        "given": "Viorel",
        "family": "Munteanu"
      },
      {
        "given": "Timur",
        "family": "Suhodolschi"
      },
      {
        "given": "Dumitru",
        "family": "Ciorba"
      },
      {
        "given": "Eleazar",
        "family": "Eskin"
      },
      {
        "given": "Wei",
        "family": "Wang"
      },
      {
        "given": "Serghei",
        "family": "Mangul"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023,
          12,
          20
        ]
      ]
    },
    "URL": "https://doi.org/gtbgvk",
    "id": "uYvzQA7w",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/2023.12.19.572483"
  },
  {
    "publisher": "SAGE Publications",
    "issue": "6",
    "abstract": "<jats:p>An academic scientist’s professional success depends on publishing. Publishing norms emphasize novel, positive results. As such, disciplinary incentives encourage design, analysis, and reporting decisions that elicit positive results and ignore negative results. Prior reports demonstrate how these incentives inflate the rate of false effects in published science. When incentives favor novelty over replication, false results persist in the literature unchallenged, reducing efficiency in knowledge accumulation. Previous suggestions to address this problem are unlikely to be effective. For example, a journal of negative results publishes otherwise unpublishable reports. This enshrines the low status of the journal and its content. The persistence of false findings can be meliorated with strategies that make the fundamental but abstract accuracy motive—getting it right—competitive with the more tangible and concrete incentive—getting it published. This article develops strategies for improving scientific practices and knowledge accumulation that account for ordinary human motivations and biases.</jats:p>",
    "DOI": "10.1177/1745691612459058",
    "type": "article-journal",
    "page": "615-631",
    "source": "Crossref",
    "title": "Scientific Utopia",
    "volume": "7",
    "author": [
      {
        "given": "Brian A.",
        "family": "Nosek"
      },
      {
        "given": "Jeffrey R.",
        "family": "Spies"
      },
      {
        "given": "Matt",
        "family": "Motyl"
      }
    ],
    "container-title": "Perspectives on Psychological Science",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2012,
          11
        ]
      ]
    },
    "URL": "https://doi.org/f4fc2k",
    "container-title-short": "Perspect Psychol Sci",
    "PMCID": "PMC10540222",
    "PMID": "26168121",
    "id": "JKZeMkVq",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.1177/1745691612459058"
  },
  {
    "type": "article",
    "id": "IzWFZmuQ",
    "categories": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Thoppilan",
        "given": "Romal"
      },
      {
        "family": "De Freitas",
        "given": "Daniel"
      },
      {
        "family": "Hall",
        "given": "Jamie"
      },
      {
        "family": "Shazeer",
        "given": "Noam"
      },
      {
        "family": "Kulshreshtha",
        "given": "Apoorv"
      },
      {
        "family": "Cheng",
        "given": "Heng-Tze"
      },
      {
        "family": "Jin",
        "given": "Alicia"
      },
      {
        "family": "Bos",
        "given": "Taylor"
      },
      {
        "family": "Baker",
        "given": "Leslie"
      },
      {
        "family": "Du",
        "given": "Yu"
      },
      {
        "family": "Li",
        "given": "YaGuang"
      },
      {
        "family": "Lee",
        "given": "Hongrae"
      },
      {
        "family": "Zheng",
        "given": "Huaixiu Steven"
      },
      {
        "family": "Ghafouri",
        "given": "Amin"
      },
      {
        "family": "Menegali",
        "given": "Marcelo"
      },
      {
        "family": "Huang",
        "given": "Yanping"
      },
      {
        "family": "Krikun",
        "given": "Maxim"
      },
      {
        "family": "Lepikhin",
        "given": "Dmitry"
      },
      {
        "family": "Qin",
        "given": "James"
      },
      {
        "family": "Chen",
        "given": "Dehao"
      },
      {
        "family": "Xu",
        "given": "Yuanzhong"
      },
      {
        "family": "Chen",
        "given": "Zhifeng"
      },
      {
        "family": "Roberts",
        "given": "Adam"
      },
      {
        "family": "Bosma",
        "given": "Maarten"
      },
      {
        "family": "Zhao",
        "given": "Vincent"
      },
      {
        "family": "Zhou",
        "given": "Yanqi"
      },
      {
        "family": "Chang",
        "given": "Chung-Ching"
      },
      {
        "family": "Krivokon",
        "given": "Igor"
      },
      {
        "family": "Rusch",
        "given": "Will"
      },
      {
        "family": "Pickett",
        "given": "Marc"
      },
      {
        "family": "Srinivasan",
        "given": "Pranesh"
      },
      {
        "family": "Man",
        "given": "Laichee"
      },
      {
        "family": "Meier-Hellstern",
        "given": "Kathleen"
      },
      {
        "family": "Morris",
        "given": "Meredith Ringel"
      },
      {
        "family": "Doshi",
        "given": "Tulsee"
      },
      {
        "family": "Santos",
        "given": "Renelito Delos"
      },
      {
        "family": "Duke",
        "given": "Toju"
      },
      {
        "family": "Soraker",
        "given": "Johnny"
      },
      {
        "family": "Zevenbergen",
        "given": "Ben"
      },
      {
        "family": "Prabhakaran",
        "given": "Vinodkumar"
      },
      {
        "family": "Diaz",
        "given": "Mark"
      },
      {
        "family": "Hutchinson",
        "given": "Ben"
      },
      {
        "family": "Olson",
        "given": "Kristen"
      },
      {
        "family": "Molina",
        "given": "Alejandra"
      },
      {
        "family": "Hoffman-John",
        "given": "Erin"
      },
      {
        "family": "Lee",
        "given": "Josh"
      },
      {
        "family": "Aroyo",
        "given": "Lora"
      },
      {
        "family": "Rajakumar",
        "given": "Ravi"
      },
      {
        "family": "Butryna",
        "given": "Alena"
      },
      {
        "family": "Lamm",
        "given": "Matthew"
      },
      {
        "family": "Kuzmina",
        "given": "Viktoriya"
      },
      {
        "family": "Fenton",
        "given": "Joe"
      },
      {
        "family": "Cohen",
        "given": "Aaron"
      },
      {
        "family": "Bernstein",
        "given": "Rachel"
      },
      {
        "family": "Kurzweil",
        "given": "Ray"
      },
      {
        "family": "Aguera-Arcas",
        "given": "Blaise"
      },
      {
        "family": "Cui",
        "given": "Claire"
      },
      {
        "family": "Croak",
        "given": "Marian"
      },
      {
        "family": "Chi",
        "given": "Ed"
      },
      {
        "family": "Le",
        "given": "Quoc"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "abstract": "We present LaMDA: Language Models for Dialog Applications. LaMDA is a family of Transformer-based neural language models specialized for dialog, which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text. While model scaling alone can improve quality, it shows less improvements on safety and factual grounding. We demonstrate that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding. The first challenge, safety, involves ensuring that the model's responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. We quantify safety using a metric based on an illustrative set of human values, and we find that filtering candidate responses using a LaMDA classifier fine-tuned with a small amount of crowdworker-annotated data offers a promising approach to improving model safety. The second challenge, factual grounding, involves enabling the model to consult external knowledge sources, such as an information retrieval system, a language translator, and a calculator. We quantify factuality using a groundedness metric, and we find that our approach enables the model to generate responses grounded in known sources, rather than responses that merely sound plausible. Finally, we explore the use of LaMDA in the domains of education and content recommendations, and analyze their helpfulness and role consistency.",
    "DOI": "10.48550/arxiv.2201.08239",
    "publisher": "arXiv",
    "title": "LaMDA: Language Models for Dialog Applications",
    "URL": "https://doi.org/kmfc",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2201.08239"
  },
  {
    "type": "article",
    "id": "JIjeWPOb",
    "categories": [
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Chowdhery",
        "given": "Aakanksha"
      },
      {
        "family": "Narang",
        "given": "Sharan"
      },
      {
        "family": "Devlin",
        "given": "Jacob"
      },
      {
        "family": "Bosma",
        "given": "Maarten"
      },
      {
        "family": "Mishra",
        "given": "Gaurav"
      },
      {
        "family": "Roberts",
        "given": "Adam"
      },
      {
        "family": "Barham",
        "given": "Paul"
      },
      {
        "family": "Chung",
        "given": "Hyung Won"
      },
      {
        "family": "Sutton",
        "given": "Charles"
      },
      {
        "family": "Gehrmann",
        "given": "Sebastian"
      },
      {
        "family": "Schuh",
        "given": "Parker"
      },
      {
        "family": "Shi",
        "given": "Kensen"
      },
      {
        "family": "Tsvyashchenko",
        "given": "Sasha"
      },
      {
        "family": "Maynez",
        "given": "Joshua"
      },
      {
        "family": "Rao",
        "given": "Abhishek"
      },
      {
        "family": "Barnes",
        "given": "Parker"
      },
      {
        "family": "Tay",
        "given": "Yi"
      },
      {
        "family": "Shazeer",
        "given": "Noam"
      },
      {
        "family": "Prabhakaran",
        "given": "Vinodkumar"
      },
      {
        "family": "Reif",
        "given": "Emily"
      },
      {
        "family": "Du",
        "given": "Nan"
      },
      {
        "family": "Hutchinson",
        "given": "Ben"
      },
      {
        "family": "Pope",
        "given": "Reiner"
      },
      {
        "family": "Bradbury",
        "given": "James"
      },
      {
        "family": "Austin",
        "given": "Jacob"
      },
      {
        "family": "Isard",
        "given": "Michael"
      },
      {
        "family": "Gur-Ari",
        "given": "Guy"
      },
      {
        "family": "Yin",
        "given": "Pengcheng"
      },
      {
        "family": "Duke",
        "given": "Toju"
      },
      {
        "family": "Levskaya",
        "given": "Anselm"
      },
      {
        "family": "Ghemawat",
        "given": "Sanjay"
      },
      {
        "family": "Dev",
        "given": "Sunipa"
      },
      {
        "family": "Michalewski",
        "given": "Henryk"
      },
      {
        "family": "Garcia",
        "given": "Xavier"
      },
      {
        "family": "Misra",
        "given": "Vedant"
      },
      {
        "family": "Robinson",
        "given": "Kevin"
      },
      {
        "family": "Fedus",
        "given": "Liam"
      },
      {
        "family": "Zhou",
        "given": "Denny"
      },
      {
        "family": "Ippolito",
        "given": "Daphne"
      },
      {
        "family": "Luan",
        "given": "David"
      },
      {
        "family": "Lim",
        "given": "Hyeontaek"
      },
      {
        "family": "Zoph",
        "given": "Barret"
      },
      {
        "family": "Spiridonov",
        "given": "Alexander"
      },
      {
        "family": "Sepassi",
        "given": "Ryan"
      },
      {
        "family": "Dohan",
        "given": "David"
      },
      {
        "family": "Agrawal",
        "given": "Shivani"
      },
      {
        "family": "Omernick",
        "given": "Mark"
      },
      {
        "family": "Dai",
        "given": "Andrew M."
      },
      {
        "family": "Pillai",
        "given": "Thanumalayan Sankaranarayana"
      },
      {
        "family": "Pellat",
        "given": "Marie"
      },
      {
        "family": "Lewkowycz",
        "given": "Aitor"
      },
      {
        "family": "Moreira",
        "given": "Erica"
      },
      {
        "family": "Child",
        "given": "Rewon"
      },
      {
        "family": "Polozov",
        "given": "Oleksandr"
      },
      {
        "family": "Lee",
        "given": "Katherine"
      },
      {
        "family": "Zhou",
        "given": "Zongwei"
      },
      {
        "family": "Wang",
        "given": "Xuezhi"
      },
      {
        "family": "Saeta",
        "given": "Brennan"
      },
      {
        "family": "Diaz",
        "given": "Mark"
      },
      {
        "family": "Firat",
        "given": "Orhan"
      },
      {
        "family": "Catasta",
        "given": "Michele"
      },
      {
        "family": "Wei",
        "given": "Jason"
      },
      {
        "family": "Meier-Hellstern",
        "given": "Kathy"
      },
      {
        "family": "Eck",
        "given": "Douglas"
      },
      {
        "family": "Dean",
        "given": "Jeff"
      },
      {
        "family": "Petrov",
        "given": "Slav"
      },
      {
        "family": "Fiedel",
        "given": "Noah"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "abstract": "Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.",
    "DOI": "10.48550/arxiv.2204.02311",
    "publisher": "arXiv",
    "title": "PaLM: Scaling Language Modeling with Pathways",
    "URL": "https://doi.org/kfxf",
    "version": "5",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2204.02311"
  },
  {
    "type": "article",
    "id": "UNYcEMOH",
    "categories": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "White",
        "given": "Jules"
      },
      {
        "family": "Fu",
        "given": "Quchen"
      },
      {
        "family": "Hays",
        "given": "Sam"
      },
      {
        "family": "Sandborn",
        "given": "Michael"
      },
      {
        "family": "Olea",
        "given": "Carlos"
      },
      {
        "family": "Gilbert",
        "given": "Henry"
      },
      {
        "family": "Elnashar",
        "given": "Ashraf"
      },
      {
        "family": "Spencer-Smith",
        "given": "Jesse"
      },
      {
        "family": "Schmidt",
        "given": "Douglas C."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM. This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs. Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs. This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks. First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains. Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations. Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.",
    "DOI": "10.48550/arxiv.2302.11382",
    "publisher": "arXiv",
    "title": "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT",
    "URL": "https://doi.org/grxct8",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2302.11382"
  },
  {
    "type": "article",
    "id": "17lpGtuH5",
    "categories": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "OpenAI"
      },
      {
        "family": ":"
      },
      {
        "family": "Achiam",
        "given": "Josh"
      },
      {
        "family": "Adler",
        "given": "Steven"
      },
      {
        "family": "Agarwal",
        "given": "Sandhini"
      },
      {
        "family": "Ahmad",
        "given": "Lama"
      },
      {
        "family": "Akkaya",
        "given": "Ilge"
      },
      {
        "family": "Aleman",
        "given": "Florencia Leoni"
      },
      {
        "family": "Almeida",
        "given": "Diogo"
      },
      {
        "family": "Altenschmidt",
        "given": "Janko"
      },
      {
        "family": "Altman",
        "given": "Sam"
      },
      {
        "family": "Anadkat",
        "given": "Shyamal"
      },
      {
        "family": "Avila",
        "given": "Red"
      },
      {
        "family": "Babuschkin",
        "given": "Igor"
      },
      {
        "family": "Balaji",
        "given": "Suchir"
      },
      {
        "family": "Balcom",
        "given": "Valerie"
      },
      {
        "family": "Baltescu",
        "given": "Paul"
      },
      {
        "family": "Bao",
        "given": "Haiming"
      },
      {
        "family": "Bavarian",
        "given": "Mo"
      },
      {
        "family": "Belgum",
        "given": "Jeff"
      },
      {
        "family": "Bello",
        "given": "Irwan"
      },
      {
        "family": "Berdine",
        "given": "Jake"
      },
      {
        "family": "Bernadett-Shapiro",
        "given": "Gabriel"
      },
      {
        "family": "Berner",
        "given": "Christopher"
      },
      {
        "family": "Bogdonoff",
        "given": "Lenny"
      },
      {
        "family": "Boiko",
        "given": "Oleg"
      },
      {
        "family": "Boyd",
        "given": "Madelaine"
      },
      {
        "family": "Brakman",
        "given": "Anna-Luisa"
      },
      {
        "family": "Brockman",
        "given": "Greg"
      },
      {
        "family": "Brooks",
        "given": "Tim"
      },
      {
        "family": "Brundage",
        "given": "Miles"
      },
      {
        "family": "Button",
        "given": "Kevin"
      },
      {
        "family": "Cai",
        "given": "Trevor"
      },
      {
        "family": "Campbell",
        "given": "Rosie"
      },
      {
        "family": "Cann",
        "given": "Andrew"
      },
      {
        "family": "Carey",
        "given": "Brittany"
      },
      {
        "family": "Carlson",
        "given": "Chelsea"
      },
      {
        "family": "Carmichael",
        "given": "Rory"
      },
      {
        "family": "Chan",
        "given": "Brooke"
      },
      {
        "family": "Chang",
        "given": "Che"
      },
      {
        "family": "Chantzis",
        "given": "Fotis"
      },
      {
        "family": "Chen",
        "given": "Derek"
      },
      {
        "family": "Chen",
        "given": "Sully"
      },
      {
        "family": "Chen",
        "given": "Ruby"
      },
      {
        "family": "Chen",
        "given": "Jason"
      },
      {
        "family": "Chen",
        "given": "Mark"
      },
      {
        "family": "Chess",
        "given": "Ben"
      },
      {
        "family": "Cho",
        "given": "Chester"
      },
      {
        "family": "Chu",
        "given": "Casey"
      },
      {
        "family": "Chung",
        "given": "Hyung Won"
      },
      {
        "family": "Cummings",
        "given": "Dave"
      },
      {
        "family": "Currier",
        "given": "Jeremiah"
      },
      {
        "family": "Dai",
        "given": "Yunxing"
      },
      {
        "family": "Decareaux",
        "given": "Cory"
      },
      {
        "family": "Degry",
        "given": "Thomas"
      },
      {
        "family": "Deutsch",
        "given": "Noah"
      },
      {
        "family": "Deville",
        "given": "Damien"
      },
      {
        "family": "Dhar",
        "given": "Arka"
      },
      {
        "family": "Dohan",
        "given": "David"
      },
      {
        "family": "Dowling",
        "given": "Steve"
      },
      {
        "family": "Dunning",
        "given": "Sheila"
      },
      {
        "family": "Ecoffet",
        "given": "Adrien"
      },
      {
        "family": "Eleti",
        "given": "Atty"
      },
      {
        "family": "Eloundou",
        "given": "Tyna"
      },
      {
        "family": "Farhi",
        "given": "David"
      },
      {
        "family": "Fedus",
        "given": "Liam"
      },
      {
        "family": "Felix",
        "given": "Niko"
      },
      {
        "family": "Fishman",
        "given": "Simón Posada"
      },
      {
        "family": "Forte",
        "given": "Juston"
      },
      {
        "family": "Fulford",
        "given": "Isabella"
      },
      {
        "family": "Gao",
        "given": "Leo"
      },
      {
        "family": "Georges",
        "given": "Elie"
      },
      {
        "family": "Gibson",
        "given": "Christian"
      },
      {
        "family": "Goel",
        "given": "Vik"
      },
      {
        "family": "Gogineni",
        "given": "Tarun"
      },
      {
        "family": "Goh",
        "given": "Gabriel"
      },
      {
        "family": "Gontijo-Lopes",
        "given": "Rapha"
      },
      {
        "family": "Gordon",
        "given": "Jonathan"
      },
      {
        "family": "Grafstein",
        "given": "Morgan"
      },
      {
        "family": "Gray",
        "given": "Scott"
      },
      {
        "family": "Greene",
        "given": "Ryan"
      },
      {
        "family": "Gross",
        "given": "Joshua"
      },
      {
        "family": "Gu",
        "given": "Shixiang Shane"
      },
      {
        "family": "Guo",
        "given": "Yufei"
      },
      {
        "family": "Hallacy",
        "given": "Chris"
      },
      {
        "family": "Han",
        "given": "Jesse"
      },
      {
        "family": "Harris",
        "given": "Jeff"
      },
      {
        "family": "He",
        "given": "Yuchen"
      },
      {
        "family": "Heaton",
        "given": "Mike"
      },
      {
        "family": "Heidecke",
        "given": "Johannes"
      },
      {
        "family": "Hesse",
        "given": "Chris"
      },
      {
        "family": "Hickey",
        "given": "Alan"
      },
      {
        "family": "Hickey",
        "given": "Wade"
      },
      {
        "family": "Hoeschele",
        "given": "Peter"
      },
      {
        "family": "Houghton",
        "given": "Brandon"
      },
      {
        "family": "Hsu",
        "given": "Kenny"
      },
      {
        "family": "Hu",
        "given": "Shengli"
      },
      {
        "family": "Hu",
        "given": "Xin"
      },
      {
        "family": "Huizinga",
        "given": "Joost"
      },
      {
        "family": "Jain",
        "given": "Shantanu"
      },
      {
        "family": "Jain",
        "given": "Shawn"
      },
      {
        "family": "Jang",
        "given": "Joanne"
      },
      {
        "family": "Jiang",
        "given": "Angela"
      },
      {
        "family": "Jiang",
        "given": "Roger"
      },
      {
        "family": "Jin",
        "given": "Haozhun"
      },
      {
        "family": "Jin",
        "given": "Denny"
      },
      {
        "family": "Jomoto",
        "given": "Shino"
      },
      {
        "family": "Jonn",
        "given": "Billie"
      },
      {
        "family": "Jun",
        "given": "Heewoo"
      },
      {
        "family": "Kaftan",
        "given": "Tomer"
      },
      {
        "family": "Kaiser",
        "given": "Łukasz"
      },
      {
        "family": "Kamali",
        "given": "Ali"
      },
      {
        "family": "Kanitscheider",
        "given": "Ingmar"
      },
      {
        "family": "Keskar",
        "given": "Nitish Shirish"
      },
      {
        "family": "Khan",
        "given": "Tabarak"
      },
      {
        "family": "Kilpatrick",
        "given": "Logan"
      },
      {
        "family": "Kim",
        "given": "Jong Wook"
      },
      {
        "family": "Kim",
        "given": "Christina"
      },
      {
        "family": "Kim",
        "given": "Yongjik"
      },
      {
        "family": "Kirchner",
        "given": "Hendrik"
      },
      {
        "family": "Kiros",
        "given": "Jamie"
      },
      {
        "family": "Knight",
        "given": "Matt"
      },
      {
        "family": "Kokotajlo",
        "given": "Daniel"
      },
      {
        "family": "Kondraciuk",
        "given": "Łukasz"
      },
      {
        "family": "Kondrich",
        "given": "Andrew"
      },
      {
        "family": "Konstantinidis",
        "given": "Aris"
      },
      {
        "family": "Kosic",
        "given": "Kyle"
      },
      {
        "family": "Krueger",
        "given": "Gretchen"
      },
      {
        "family": "Kuo",
        "given": "Vishal"
      },
      {
        "family": "Lampe",
        "given": "Michael"
      },
      {
        "family": "Lan",
        "given": "Ikai"
      },
      {
        "family": "Lee",
        "given": "Teddy"
      },
      {
        "family": "Leike",
        "given": "Jan"
      },
      {
        "family": "Leung",
        "given": "Jade"
      },
      {
        "family": "Levy",
        "given": "Daniel"
      },
      {
        "family": "Li",
        "given": "Chak Ming"
      },
      {
        "family": "Lim",
        "given": "Rachel"
      },
      {
        "family": "Lin",
        "given": "Molly"
      },
      {
        "family": "Lin",
        "given": "Stephanie"
      },
      {
        "family": "Litwin",
        "given": "Mateusz"
      },
      {
        "family": "Lopez",
        "given": "Theresa"
      },
      {
        "family": "Lowe",
        "given": "Ryan"
      },
      {
        "family": "Lue",
        "given": "Patricia"
      },
      {
        "family": "Makanju",
        "given": "Anna"
      },
      {
        "family": "Malfacini",
        "given": "Kim"
      },
      {
        "family": "Manning",
        "given": "Sam"
      },
      {
        "family": "Markov",
        "given": "Todor"
      },
      {
        "family": "Markovski",
        "given": "Yaniv"
      },
      {
        "family": "Martin",
        "given": "Bianca"
      },
      {
        "family": "Mayer",
        "given": "Katie"
      },
      {
        "family": "Mayne",
        "given": "Andrew"
      },
      {
        "family": "McGrew",
        "given": "Bob"
      },
      {
        "family": "McKinney",
        "given": "Scott Mayer"
      },
      {
        "family": "McLeavey",
        "given": "Christine"
      },
      {
        "family": "McMillan",
        "given": "Paul"
      },
      {
        "family": "McNeil",
        "given": "Jake"
      },
      {
        "family": "Medina",
        "given": "David"
      },
      {
        "family": "Mehta",
        "given": "Aalok"
      },
      {
        "family": "Menick",
        "given": "Jacob"
      },
      {
        "family": "Metz",
        "given": "Luke"
      },
      {
        "family": "Mishchenko",
        "given": "Andrey"
      },
      {
        "family": "Mishkin",
        "given": "Pamela"
      },
      {
        "family": "Monaco",
        "given": "Vinnie"
      },
      {
        "family": "Morikawa",
        "given": "Evan"
      },
      {
        "family": "Mossing",
        "given": "Daniel"
      },
      {
        "family": "Mu",
        "given": "Tong"
      },
      {
        "family": "Murati",
        "given": "Mira"
      },
      {
        "family": "Murk",
        "given": "Oleg"
      },
      {
        "family": "Mély",
        "given": "David"
      },
      {
        "family": "Nair",
        "given": "Ashvin"
      },
      {
        "family": "Nakano",
        "given": "Reiichiro"
      },
      {
        "family": "Nayak",
        "given": "Rajeev"
      },
      {
        "family": "Neelakantan",
        "given": "Arvind"
      },
      {
        "family": "Ngo",
        "given": "Richard"
      },
      {
        "family": "Noh",
        "given": "Hyeonwoo"
      },
      {
        "family": "Ouyang",
        "given": "Long"
      },
      {
        "family": "O'Keefe",
        "given": "Cullen"
      },
      {
        "family": "Pachocki",
        "given": "Jakub"
      },
      {
        "family": "Paino",
        "given": "Alex"
      },
      {
        "family": "Palermo",
        "given": "Joe"
      },
      {
        "family": "Pantuliano",
        "given": "Ashley"
      },
      {
        "family": "Parascandolo",
        "given": "Giambattista"
      },
      {
        "family": "Parish",
        "given": "Joel"
      },
      {
        "family": "Parparita",
        "given": "Emy"
      },
      {
        "family": "Passos",
        "given": "Alex"
      },
      {
        "family": "Pavlov",
        "given": "Mikhail"
      },
      {
        "family": "Peng",
        "given": "Andrew"
      },
      {
        "family": "Perelman",
        "given": "Adam"
      },
      {
        "family": "Peres",
        "given": "Filipe de Avila Belbute"
      },
      {
        "family": "Petrov",
        "given": "Michael"
      },
      {
        "family": "Pinto",
        "given": "Henrique Ponde de Oliveira"
      },
      {
        "family": "Michael"
      },
      {
        "literal": "Pokorny"
      },
      {
        "family": "Pokrass",
        "given": "Michelle"
      },
      {
        "family": "Pong",
        "given": "Vitchyr"
      },
      {
        "family": "Powell",
        "given": "Tolly"
      },
      {
        "family": "Power",
        "given": "Alethea"
      },
      {
        "family": "Power",
        "given": "Boris"
      },
      {
        "family": "Proehl",
        "given": "Elizabeth"
      },
      {
        "family": "Puri",
        "given": "Raul"
      },
      {
        "family": "Radford",
        "given": "Alec"
      },
      {
        "family": "Rae",
        "given": "Jack"
      },
      {
        "family": "Ramesh",
        "given": "Aditya"
      },
      {
        "family": "Raymond",
        "given": "Cameron"
      },
      {
        "family": "Real",
        "given": "Francis"
      },
      {
        "family": "Rimbach",
        "given": "Kendra"
      },
      {
        "family": "Ross",
        "given": "Carl"
      },
      {
        "family": "Rotsted",
        "given": "Bob"
      },
      {
        "family": "Roussez",
        "given": "Henri"
      },
      {
        "family": "Ryder",
        "given": "Nick"
      },
      {
        "family": "Saltarelli",
        "given": "Mario"
      },
      {
        "family": "Sanders",
        "given": "Ted"
      },
      {
        "family": "Santurkar",
        "given": "Shibani"
      },
      {
        "family": "Sastry",
        "given": "Girish"
      },
      {
        "family": "Schmidt",
        "given": "Heather"
      },
      {
        "family": "Schnurr",
        "given": "David"
      },
      {
        "family": "Schulman",
        "given": "John"
      },
      {
        "family": "Selsam",
        "given": "Daniel"
      },
      {
        "family": "Sheppard",
        "given": "Kyla"
      },
      {
        "family": "Sherbakov",
        "given": "Toki"
      },
      {
        "family": "Shieh",
        "given": "Jessica"
      },
      {
        "family": "Shoker",
        "given": "Sarah"
      },
      {
        "family": "Shyam",
        "given": "Pranav"
      },
      {
        "family": "Sidor",
        "given": "Szymon"
      },
      {
        "family": "Sigler",
        "given": "Eric"
      },
      {
        "family": "Simens",
        "given": "Maddie"
      },
      {
        "family": "Sitkin",
        "given": "Jordan"
      },
      {
        "family": "Slama",
        "given": "Katarina"
      },
      {
        "family": "Sohl",
        "given": "Ian"
      },
      {
        "family": "Sokolowsky",
        "given": "Benjamin"
      },
      {
        "family": "Song",
        "given": "Yang"
      },
      {
        "family": "Staudacher",
        "given": "Natalie"
      },
      {
        "family": "Such",
        "given": "Felipe Petroski"
      },
      {
        "family": "Summers",
        "given": "Natalie"
      },
      {
        "family": "Sutskever",
        "given": "Ilya"
      },
      {
        "family": "Tang",
        "given": "Jie"
      },
      {
        "family": "Tezak",
        "given": "Nikolas"
      },
      {
        "family": "Thompson",
        "given": "Madeleine"
      },
      {
        "family": "Tillet",
        "given": "Phil"
      },
      {
        "family": "Tootoonchian",
        "given": "Amin"
      },
      {
        "family": "Tseng",
        "given": "Elizabeth"
      },
      {
        "family": "Tuggle",
        "given": "Preston"
      },
      {
        "family": "Turley",
        "given": "Nick"
      },
      {
        "family": "Tworek",
        "given": "Jerry"
      },
      {
        "family": "Uribe",
        "given": "Juan Felipe Cerón"
      },
      {
        "family": "Vallone",
        "given": "Andrea"
      },
      {
        "family": "Vijayvergiya",
        "given": "Arun"
      },
      {
        "family": "Voss",
        "given": "Chelsea"
      },
      {
        "family": "Wainwright",
        "given": "Carroll"
      },
      {
        "family": "Wang",
        "given": "Justin Jay"
      },
      {
        "family": "Wang",
        "given": "Alvin"
      },
      {
        "family": "Wang",
        "given": "Ben"
      },
      {
        "family": "Ward",
        "given": "Jonathan"
      },
      {
        "family": "Wei",
        "given": "Jason"
      },
      {
        "family": "Weinmann",
        "given": "CJ"
      },
      {
        "family": "Welihinda",
        "given": "Akila"
      },
      {
        "family": "Welinder",
        "given": "Peter"
      },
      {
        "family": "Weng",
        "given": "Jiayi"
      },
      {
        "family": "Weng",
        "given": "Lilian"
      },
      {
        "family": "Wiethoff",
        "given": "Matt"
      },
      {
        "family": "Willner",
        "given": "Dave"
      },
      {
        "family": "Winter",
        "given": "Clemens"
      },
      {
        "family": "Wolrich",
        "given": "Samuel"
      },
      {
        "family": "Wong",
        "given": "Hannah"
      },
      {
        "family": "Workman",
        "given": "Lauren"
      },
      {
        "family": "Wu",
        "given": "Sherwin"
      },
      {
        "family": "Wu",
        "given": "Jeff"
      },
      {
        "family": "Wu",
        "given": "Michael"
      },
      {
        "family": "Xiao",
        "given": "Kai"
      },
      {
        "family": "Xu",
        "given": "Tao"
      },
      {
        "family": "Yoo",
        "given": "Sarah"
      },
      {
        "family": "Yu",
        "given": "Kevin"
      },
      {
        "family": "Yuan",
        "given": "Qiming"
      },
      {
        "family": "Zaremba",
        "given": "Wojciech"
      },
      {
        "family": "Zellers",
        "given": "Rowan"
      },
      {
        "family": "Zhang",
        "given": "Chong"
      },
      {
        "family": "Zhang",
        "given": "Marvin"
      },
      {
        "family": "Zhao",
        "given": "Shengjia"
      },
      {
        "family": "Zheng",
        "given": "Tianhao"
      },
      {
        "family": "Zhuang",
        "given": "Juntang"
      },
      {
        "family": "Zhuk",
        "given": "William"
      },
      {
        "family": "Zoph",
        "given": "Barret"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
    "DOI": "10.48550/arxiv.2303.08774",
    "publisher": "arXiv",
    "title": "GPT-4 Technical Report",
    "URL": "https://doi.org/grx4cb",
    "version": "4",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2303.08774"
  },
  {
    "type": "article",
    "id": "1BzQcjRCZ",
    "categories": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Shen",
        "given": "Yongliang"
      },
      {
        "family": "Song",
        "given": "Kaitao"
      },
      {
        "family": "Tan",
        "given": "Xu"
      },
      {
        "family": "Li",
        "given": "Dongsheng"
      },
      {
        "family": "Lu",
        "given": "Weiming"
      },
      {
        "family": "Zhuang",
        "given": "Yueting"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Solving complicated AI tasks with different domains and modalities is a key step toward artificial general intelligence. While there are numerous AI models available for various domains and modalities, they cannot handle complicated AI tasks autonomously. Considering large language models (LLMs) have exhibited exceptional abilities in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks, with language serving as a generic interface to empower this. Based on this philosophy, we present HuggingGPT, an LLM-powered agent that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT can tackle a wide range of sophisticated AI tasks spanning different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards the realization of artificial general intelligence.",
    "DOI": "10.48550/arxiv.2303.17580",
    "publisher": "arXiv",
    "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face",
    "URL": "https://doi.org/gskd97",
    "version": "4",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2303.17580"
  },
  {
    "type": "article",
    "id": "hHuKg12k",
    "categories": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Patil",
        "given": "Shishir G."
      },
      {
        "family": "Zhang",
        "given": "Tianjun"
      },
      {
        "family": "Wang",
        "given": "Xin"
      },
      {
        "family": "Gonzalez",
        "given": "Joseph E."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis. However, their potential to effectively use tools via API calls remains unfulfilled. This is a challenging task even for today's state-of-the-art LLMs such as GPT-4, largely due to their inability to generate accurate input arguments and their tendency to hallucinate the wrong usage of an API call. We release Gorilla, a finetuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls. When combined with a document retriever, Gorilla demonstrates a strong capability to adapt to test-time document changes, enabling flexible user updates or version changes. It also substantially mitigates the issue of hallucination, commonly encountered when prompting LLMs directly. To evaluate the model's ability, we introduce APIBench, a comprehensive dataset consisting of HuggingFace, TorchHub, and TensorHub APIs. The successful integration of the retrieval system with Gorilla demonstrates the potential for LLMs to use tools more accurately, keep up with frequently updated documentation, and consequently increase the reliability and applicability of their outputs. Gorilla's code, model, data, and demo are available at https://gorilla.cs.berkeley.edu",
    "DOI": "10.48550/arxiv.2305.15334",
    "publisher": "arXiv",
    "title": "Gorilla: Large Language Model Connected with Massive APIs",
    "URL": "https://doi.org/gtbgvm",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2305.15334"
  },
  {
    "type": "article",
    "id": "SgpSThMj",
    "categories": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Touvron",
        "given": "Hugo"
      },
      {
        "family": "Martin",
        "given": "Louis"
      },
      {
        "family": "Stone",
        "given": "Kevin"
      },
      {
        "family": "Albert",
        "given": "Peter"
      },
      {
        "family": "Almahairi",
        "given": "Amjad"
      },
      {
        "family": "Babaei",
        "given": "Yasmine"
      },
      {
        "family": "Bashlykov",
        "given": "Nikolay"
      },
      {
        "family": "Batra",
        "given": "Soumya"
      },
      {
        "family": "Bhargava",
        "given": "Prajjwal"
      },
      {
        "family": "Bhosale",
        "given": "Shruti"
      },
      {
        "family": "Bikel",
        "given": "Dan"
      },
      {
        "family": "Blecher",
        "given": "Lukas"
      },
      {
        "family": "Ferrer",
        "given": "Cristian Canton"
      },
      {
        "family": "Chen",
        "given": "Moya"
      },
      {
        "family": "Cucurull",
        "given": "Guillem"
      },
      {
        "family": "Esiobu",
        "given": "David"
      },
      {
        "family": "Fernandes",
        "given": "Jude"
      },
      {
        "family": "Fu",
        "given": "Jeremy"
      },
      {
        "family": "Fu",
        "given": "Wenyin"
      },
      {
        "family": "Fuller",
        "given": "Brian"
      },
      {
        "family": "Gao",
        "given": "Cynthia"
      },
      {
        "family": "Goswami",
        "given": "Vedanuj"
      },
      {
        "family": "Goyal",
        "given": "Naman"
      },
      {
        "family": "Hartshorn",
        "given": "Anthony"
      },
      {
        "family": "Hosseini",
        "given": "Saghar"
      },
      {
        "family": "Hou",
        "given": "Rui"
      },
      {
        "family": "Inan",
        "given": "Hakan"
      },
      {
        "family": "Kardas",
        "given": "Marcin"
      },
      {
        "family": "Kerkez",
        "given": "Viktor"
      },
      {
        "family": "Khabsa",
        "given": "Madian"
      },
      {
        "family": "Kloumann",
        "given": "Isabel"
      },
      {
        "family": "Korenev",
        "given": "Artem"
      },
      {
        "family": "Koura",
        "given": "Punit Singh"
      },
      {
        "family": "Lachaux",
        "given": "Marie-Anne"
      },
      {
        "family": "Lavril",
        "given": "Thibaut"
      },
      {
        "family": "Lee",
        "given": "Jenya"
      },
      {
        "family": "Liskovich",
        "given": "Diana"
      },
      {
        "family": "Lu",
        "given": "Yinghai"
      },
      {
        "family": "Mao",
        "given": "Yuning"
      },
      {
        "family": "Martinet",
        "given": "Xavier"
      },
      {
        "family": "Mihaylov",
        "given": "Todor"
      },
      {
        "family": "Mishra",
        "given": "Pushkar"
      },
      {
        "family": "Molybog",
        "given": "Igor"
      },
      {
        "family": "Nie",
        "given": "Yixin"
      },
      {
        "family": "Poulton",
        "given": "Andrew"
      },
      {
        "family": "Reizenstein",
        "given": "Jeremy"
      },
      {
        "family": "Rungta",
        "given": "Rashi"
      },
      {
        "family": "Saladi",
        "given": "Kalyan"
      },
      {
        "family": "Schelten",
        "given": "Alan"
      },
      {
        "family": "Silva",
        "given": "Ruan"
      },
      {
        "family": "Smith",
        "given": "Eric Michael"
      },
      {
        "family": "Subramanian",
        "given": "Ranjan"
      },
      {
        "family": "Tan",
        "given": "Xiaoqing Ellen"
      },
      {
        "family": "Tang",
        "given": "Binh"
      },
      {
        "family": "Taylor",
        "given": "Ross"
      },
      {
        "family": "Williams",
        "given": "Adina"
      },
      {
        "family": "Kuan",
        "given": "Jian Xiang"
      },
      {
        "family": "Xu",
        "given": "Puxin"
      },
      {
        "family": "Yan",
        "given": "Zheng"
      },
      {
        "family": "Zarov",
        "given": "Iliyan"
      },
      {
        "family": "Zhang",
        "given": "Yuchen"
      },
      {
        "family": "Fan",
        "given": "Angela"
      },
      {
        "family": "Kambadur",
        "given": "Melanie"
      },
      {
        "family": "Narang",
        "given": "Sharan"
      },
      {
        "family": "Rodriguez",
        "given": "Aurelien"
      },
      {
        "family": "Stojnic",
        "given": "Robert"
      },
      {
        "family": "Edunov",
        "given": "Sergey"
      },
      {
        "family": "Scialom",
        "given": "Thomas"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.",
    "DOI": "10.48550/arxiv.2307.09288",
    "publisher": "arXiv",
    "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
    "URL": "https://doi.org/ktkj",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2307.09288"
  },
  {
    "type": "article",
    "id": "o6hUZE9J",
    "categories": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Zhu",
        "given": "Yutao"
      },
      {
        "family": "Yuan",
        "given": "Huaying"
      },
      {
        "family": "Wang",
        "given": "Shuting"
      },
      {
        "family": "Liu",
        "given": "Jiongnan"
      },
      {
        "family": "Liu",
        "given": "Wenhan"
      },
      {
        "family": "Deng",
        "given": "Chenlong"
      },
      {
        "family": "Dou",
        "given": "Zhicheng"
      },
      {
        "family": "Wen",
        "given": "Ji-Rong"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has revolutionized natural language processing due to their remarkable language understanding, generation, generalization, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, and readers. Additionally, we explore promising directions within this expanding field.",
    "DOI": "10.48550/arxiv.2308.07107",
    "publisher": "arXiv",
    "title": "Large Language Models for Information Retrieval: A Survey",
    "URL": "https://doi.org/gtbgvn",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2308.07107"
  },
  {
    "type": "article",
    "id": "lmJHElQl",
    "categories": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Wang",
        "given": "Lei"
      },
      {
        "family": "Ma",
        "given": "Chen"
      },
      {
        "family": "Feng",
        "given": "Xueyang"
      },
      {
        "family": "Zhang",
        "given": "Zeyu"
      },
      {
        "family": "Yang",
        "given": "Hao"
      },
      {
        "family": "Zhang",
        "given": "Jingsen"
      },
      {
        "family": "Chen",
        "given": "Zhiyuan"
      },
      {
        "family": "Tang",
        "given": "Jiakai"
      },
      {
        "family": "Chen",
        "given": "Xu"
      },
      {
        "family": "Lin",
        "given": "Yankai"
      },
      {
        "family": "Zhao",
        "given": "Wayne Xin"
      },
      {
        "family": "Wei",
        "given": "Zhewei"
      },
      {
        "family": "Wen",
        "given": "Ji-Rong"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at https://github.com/Paitesanshi/LLM-Agent-Survey.",
    "DOI": "10.48550/arxiv.2308.11432",
    "publisher": "arXiv",
    "title": "A Survey on Large Language Model based Autonomous Agents",
    "URL": "https://doi.org/gsv93m",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2308.11432"
  },
  {
    "type": "article",
    "id": "yT66jV6G",
    "categories": [
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Sainz",
        "given": "Oscar"
      },
      {
        "family": "Campos",
        "given": "Jon Ander"
      },
      {
        "family": "García-Ferrero",
        "given": "Iker"
      },
      {
        "family": "Etxaniz",
        "given": "Julen"
      },
      {
        "family": "de Lacalle",
        "given": "Oier Lopez"
      },
      {
        "family": "Agirre",
        "given": "Eneko"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "In this position paper, we argue that the classical evaluation on Natural Language Processing (NLP) tasks using annotated benchmarks is in trouble. The worst kind of data contamination happens when a Large Language Model (LLM) is trained on the test split of a benchmark, and then evaluated in the same benchmark. The extent of the problem is unknown, as it is not straightforward to measure. Contamination causes an overestimation of the performance of a contaminated model in a target benchmark and associated task with respect to their non-contaminated counterparts. The consequences can be very harmful, with wrong scientific conclusions being published while other correct ones are discarded. This position paper defines different levels of data contamination and argues for a community effort, including the development of automatic and semi-automatic measures to detect when data from a benchmark was exposed to a model, and suggestions for flagging papers with conclusions that are compromised by data contamination.",
    "DOI": "10.48550/arxiv.2310.18018",
    "publisher": "arXiv",
    "title": "NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark",
    "URL": "https://doi.org/gtbgvp",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2310.18018"
  },
  {
    "id": "195HIa77n",
    "type": "webpage",
    "URL": "https://www.bbc.com/news/health-65252510",
    "title": "Study reveals cancer’s ‘infinite’ ability to evolve",
    "container-title": "BBC News",
    "issued": {
      "date-parts": [
        [
          2023,
          4,
          12
        ]
      ]
    },
    "author": [
      {
        "given": "James",
        "family": "Gallagher"
      }
    ],
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: gallagher-infinite"
  },
  {
    "id": "aiaYUZ1t",
    "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "author": [
      {
        "given": "Patrick",
        "family": "Lewis"
      },
      {
        "given": "Ethan",
        "family": "Perez"
      },
      {
        "given": "Aleksandra",
        "family": "Piktus"
      },
      {
        "given": "Fabio",
        "family": "Petroni"
      },
      {
        "given": "Vladimir",
        "family": "Karpukhin"
      },
      {
        "given": "Naman",
        "family": "Goyal"
      },
      {
        "given": "Heinrich",
        "family": "Küttler"
      },
      {
        "given": "Mike",
        "family": "Lewis"
      },
      {
        "given": "Wen-tau",
        "family": "Yih"
      },
      {
        "given": "Tim",
        "family": "Rocktäschel"
      },
      {
        "given": "Sebastian",
        "family": "Riedel"
      },
      {
        "given": "Douwe",
        "family": "Kiela"
      }
    ],
    "container-title": "Advances in Neural Information Processing Systems",
    "page": "9459-9474",
    "volume": "33",
    "URL": "https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf",
    "publisher": "Curran Associates, Inc.",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: rag",
    "type": "entry"
  },
  {
    "id": "gy4YOpGJ",
    "type": "webpage",
    "abstract": "Stay up-to-date on the latest developments in artificial intelligence and natural language processing with the Official Auto-GPT Blog. Get insights into how GPT technology is transforming industries and changing the way we interact with machines. Subscribe today and join the conversation!",
    "container-title": "AutoGPT Official",
    "language": "en-US",
    "title": "AutoGPT Official",
    "URL": "https://autogpt.net/",
    "accessed": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          "2023",
          12,
          18
        ]
      ]
    },
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://autogpt.net/"
  },
  {
    "id": "14upAJPXR",
    "type": "software",
    "abstract": "The pytest framework makes it easy to write small tests, yet scales to support complex functional testing",
    "genre": "Python",
    "note": "original-date: 2015-06-15T20:28:27Z\nThis CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://github.com/pytest-dev/pytest",
    "publisher": "pytest-dev",
    "source": "GitHub",
    "title": "pytest-dev/pytest",
    "URL": "https://github.com/pytest-dev/pytest",
    "accessed": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    }
  },
  {
    "id": "mGEvmJGA",
    "type": "software",
    "abstract": "Replace OpenAI GPT with another LLM in your app by changing a single line of code. Xinference gives you the freedom to use any LLM you need. With Xinference, you're empowered to run inference with any open-source language models, speech recognition models, and multimodal models, whether in the cloud, on-premises, or even on your laptop.",
    "genre": "Python",
    "note": "original-date: 2023-06-14T07:05:04Z\nThis CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://github.com/xorbitsai/inference",
    "publisher": "Xorbits",
    "source": "GitHub",
    "title": "xorbitsai/inference",
    "URL": "https://github.com/xorbitsai/inference",
    "accessed": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    }
  },
  {
    "id": "12p6amlLS",
    "type": "webpage",
    "abstract": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "title": "Hugging Face – The AI community building the future.",
    "URL": "https://huggingface.co/",
    "accessed": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          "2024",
          1,
          8
        ]
      ]
    },
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://huggingface.co/"
  },
  {
    "id": "NicesiwN",
    "type": "webpage",
    "abstract": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "title": "Hugging Face Hub documentation",
    "URL": "https://huggingface.co/docs/hub/index",
    "accessed": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    },
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://huggingface.co/docs/hub/index"
  },
  {
    "id": "LE2GwIqT",
    "type": "webpage",
    "abstract": "Discover amazing ML apps made by the community",
    "title": "Open LLM Leaderboard - a Hugging Face Space by HuggingFaceH4",
    "URL": "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard",
    "accessed": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    },
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"
  },
  {
    "id": "C5Z1X3MG",
    "type": "webpage",
    "language": "en-US",
    "title": "Terms of use",
    "URL": "https://openai.com/policies/terms-of-use",
    "accessed": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    },
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://openai.com/policies/terms-of-use"
  },
  {
    "id": "UEmjXz02",
    "type": "webpage",
    "language": "en",
    "title": "🦜️🔗 Langchain",
    "URL": "https://python.langchain.com/",
    "accessed": {
      "date-parts": [
        [
          "2024",
          1,
          9
        ]
      ]
    },
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://python.langchain.com"
  },
  {
    "URL": "https://www.reuters.com/technology/european-data-protection-board-discussing-ai-policy-thursday-meeting-2023-04-13/",
    "type": "webpage",
    "id": "PDhRVYjU",
    "note": "This CSL Item was generated by Manubot v0.5.6 from its persistent identifier (standard_id).\nstandard_id: url:https://www.reuters.com/technology/european-data-protection-board-discussing-ai-policy-thursday-meeting-2023-04-13/"
  }
]
